El método de los mínimos cuadrados se usa para **ajustar un modelo matemático a un conjunto de datos experimentales**. El objetivo es encontrar una curva que mejor se ajuste a $m$ observaciones, generalmente asumiendo un modelo con $n$ parámetros, donde típicamente $n < m$.

**Definición:** Dados $A \in M_{m \times n}(\mathbb{R})$, $\text{y} \in \mathbb{R}^m$, decimos que un vector $\text{x}^* \in \mathbb{R}^n$ es solución del sistema $A\text{x} = \text{y}$ en el sentido de mínimos cuadrados si $$\text x^* = \arg \min_{x \in \mathbb{R}^n} |A\text{x} - \text{y}|^2_2$$ Esto es, si consideramos el residuo $\text{r} = A\text{x} - \text{y}$, entonces $\text{x}^*$ minimiza la función $$\Phi : \mathbb{R}^n \rightarrow \mathbb{R}, \qquad \Phi(\text{x}) := \sum^m_{i=1} r^2_i = \sum^m_{i=1} \left[ \left( \sum^n_{j=1} a_{ij}x_j \right) - y_i \right]^2$$
Los métodos de mínimos cuadrados se pueden clasificar según si el problema es lineal o no lineal respecto a los parámetros.

# Mínimos Cuadrados Lineales
Se asume un modelo lineal donde la función $f(t)$ se escribe como una combinación lineal de funciones base $\varphi_j(t)$.
### Ecuaciones Normales
**Teorema:** Sea $A \in M_{m \times n}(\mathbb{R})$ e $\text{y} \in \mathbb{R}^m$. Entonces, $\text{x}^* \in \mathbb{R}^n$ es solución del sistema $A\text{x} = \text{y}$ en el sentido de los mínimos cuadrados si y sólo si $$\mathbf{A^t A \text x ^* = A^t \text y}$$
**Propiedades**
- La solución $\text{x}^*$ es un **punto crítico** de la función $\Phi(\text{x}) = |A\text{x} - \text{y}|_2^2$.
- La condición $A^t A \text{x}^* = A^t \text{y}$ implica que el residuo $A\text{x}^* - \text{y}$ es **ortogonal al espacio de columnas de A** ($\text{col}(A)$).
- Geométricamente, $A\text{x}^*$ es la **proyección ortogonal** del vector de datos $\text{y}$ sobre el subespacio $\text{col}(A)$.
- Si $A$ es de rango completo ($\text{rg}(A) = n$), la matriz $A^t A$ es invertible y la solución $\text{x}^*$ es única.
- Las ecuaciones normales **no siempre son una buena opción práctica** debido al riesgo de que la matriz $A^t A$ esté **mal condicionada** (ill-conditioned).

### Descomposición QR
Los métodos de ortogonalización, como QR, ofrecen una alternativa **más estable computacionalmente** que las ecuaciones normales.
**Definición:** Dada $A \in M_{m \times n}(\mathbb{R})$ con $m \ge n$ tal que $\text{rg}(A) = n$, existen:
- Una matriz $\mathbf{Q} \in M_{m \times n}(\mathbb{R})$ cuyas columnas forman un conjunto **ortonormal** en $\mathbb{R}^m$.
- Una matriz $\mathbf{R} \in M_n(\mathbb{R})$ **triangular superior e invertible**. tales que $A = QR$.

**Propiedades y Aplicación a Mínimos Cuadrados**

- La factorización se utiliza aprovechando que las transformaciones ortogonales (por $Q$) preservan la norma euclídea, transformando el problema en $\arg \min_{x} |Rx - Q^T y|_2^2$.
- La solución $\text{x}^*$ se encuentra resolviendo el **sistema triangular superior** $R_{(1:n)} \text{x} = (Q^t \text{y})_{(1:n)}$. Este sistema se resuelve mediante **sustitución hacia atrás**.
- El valor mínimo de la norma euclídea del residuo es igual a la norma euclídea de las últimas $m-n$ entradas del vector $Q^t \text{y}$, es decir, $|r|_2 = |(Q^t \text{y})_{(n+1:m)}|_2$.
- La factorización QR se calcula de forma estable usando una sucesión de **Transformaciones de Householder**.

# Mínimos Cuadrados No Lineales

Cuando el modelo $f(t; x)$ depende de manera **no lineal** de los parámetros $x$, se busca minimizar $|r(x)|_2^2$.

- **Método de Gauss-Newton:** Este método es iterativo y aproxima la solución no lineal mediante una sucesión de **problemas de mínimos cuadrados lineales**.
- **Iteración:** En cada paso, se linealiza el residuo $r(x)$ usando la matriz Jacobiana $J_f(x_k)$. El incremento $d_k$ se calcula resolviendo el problema lineal de mínimos cuadrados: $$\mathbf{J_f(x_k) d_k = -r(x_k)}$$ y el nuevo iterado es $\mathbf{x_{k+1} = x_k + d_k}$.
